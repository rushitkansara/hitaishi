### **Hitaishi ML Model Engineering Study Report**

#### **1. Executive Summary**

This report details the development, debugging, and validation of the machine learning pipeline for the Hitaishi project. The primary objective was to create a lightweight, high-performance LSTM model for real-time prediction of 13 medical conditions using time-series vital sign data.

Through a systematic process of debugging, refactoring, and validation, a fully functional ML pipeline was established. The final quantized TensorFlow Lite model successfully meets all specified performance criteria, demonstrating high accuracy, reliability in detecting critical emergencies, and extreme efficiency for deployment on edge devices.

---

#### **2. Development and Debugging Process**

The project began with a solid codebase but required several key interventions to resolve environment conflicts, enforce consistency, and correct data processing errors.

**2.1. Dependency and Environment Resolution**

*   **Initial Problem:** The training script failed due to a `protobuf` version conflict within the Python environment. This is a common issue where different libraries (in this case, TensorFlow and various Google Cloud libraries) require incompatible versions of a shared dependency.
*   **Troubleshooting Steps:**
    1.  Initial attempts to fix the issue by downgrading and upgrading the `protobuf` library led to further dependency conflicts, a situation often referred to as "dependency hell."
    2.  A workaround using the `PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION` environment variable was also unsuccessful, indicating a deeper environment issue.
*   **Final Solution:** The root cause was identified as the script running in the system's global Python environment instead of the project's isolated virtual environment (`venv`). By activating the virtual environment (`source venv/bin/activate`), we ensured that the script used the correct, non-conflicting set of installed packages, immediately resolving the dependency errors.

**2.2. Code Refactoring for Blueprint Alignment**

To align the code with the engineering blueprint, several parts of the training script were refactored:

*   **Label Handling:** The label processing was changed from one-hot encoding to using raw integer labels. This was paired with changing the model's loss function to `sparse_categorical_crossentropy`, which is more memory-efficient and aligned with the project specifications.
*   **Optimizer Update:** The model's optimizer was updated from the legacy `tf.keras.optimizers.legacy.Adam` to the modern `tf.keras.optimizers.Adam`.
*   **Metadata Generation:** A function was added to create a `model_metadata.json` file, which programmatically logs key information about the trained model, such as its version, parameters, and final training metrics.

**2.3. Correction of "Double Normalization" Bug**

*   **Problem:** The most critical bug was discovered during the final testing phase. The test suite reported a model accuracy of only 5%, a stark contrast to the 99% accuracy seen during evaluation.
*   **Root Cause Analysis:** The investigation revealed that the test data was being normalized twice: once before being saved by the training script and a second time by the inference engine, which was designed to process raw data. This "double normalization" corrupted the input, leading to incorrect predictions.
*   **Solution:** The data processing pipeline was re-architected to be more robust. The training script was modified to save the test data in its **raw, un-normalized state**. The evaluation script was then updated to perform its own normalization. This ensures that the inference engine always receives the raw data it expects, providing a single, consistent preprocessing workflow.

---

#### **3. Final Model Characteristics and Capabilities**

The final validated model is a highly capable and efficient solution for real-time health risk prediction.

**3.1. Model Architecture**

*   The model uses a Sequential architecture with two LSTM layers (32 and 16 units, respectively).
*   `Dropout` (30%) and `BatchNormalization` are used after each LSTM layer to prevent overfitting and stabilize training.
*   The network is completed by two Dense layers, with a `softmax` activation on the final layer to output probabilities for the 13 health conditions.

**3.2. Performance Metrics**

The model's performance on the unseen test set exceeds the project's targets:

*   **Overall Accuracy:** **99.3%**
*   **Critical Emergency Detection Accuracy:** **98.75%**. This demonstrates the model's high reliability in identifying true medical emergencies.
*   **Recall for Critical Classes:** The recall for individual high-priority events like 'Heart_Attack', 'Stroke', and 'Respiratory_Distress' is exceptionally high (most at 100%), indicating a very low rate of false negatives (missed emergencies).
*   **Precision:** High precision scores (99-100%) for the 'Stable' and 'Monitor' classes show that the model is very unlikely to generate false alarms.

**3.3. Quantization and Efficiency**

The model was successfully quantized to an 8-bit integer format (INT8) using TensorFlow Lite, with the following results:

*   **Model Size Reduction:** The model size was compressed from **~173 KB to ~32 KB** (a ~5.5x reduction).
*   **Inference Speed:** The average inference time on a standard CPU is approximately **2.4 milliseconds**, which is extremely fast and well within the <10 ms target.

These characteristics make the model ideally suited for deployment on resource-constrained environments, such as mobile applications or low-power edge devices.

**3.4. Inference Engine**

The `HealthRiskPredictor` class in `inference_engine.py` provides a clean, production-ready interface for the model. It encapsulates all necessary preprocessing steps (e.g., data normalization), meaning that a user can simply provide the raw 60-second sequence of vital signs and receive a prediction without needing to worry about the underlying data transformations.

---

#### **4. Conclusion**

The Hitaishi ML pipeline has been successfully developed, debugged, and validated. The resulting model is accurate, lightweight, and fast. The systematic approach to debugging dependency conflicts and data pipeline errors has resulted in a robust and reliable system. The model is now ready for the next phase of the project, such as integration with a backend server and a real-time monitoring application.